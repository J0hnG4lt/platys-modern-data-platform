# =====================================================
# This is the {{ stack_name }} stack
# =====================================================
version: "{{ DOCKER_COMPOSE_VERSION |default(3.0) }}"

{% set __confluent_platform_version = confluent_platform_version | default('latest') -%}
{% set __zoonavigator_version = zoonavigator_version | default('latest') -%}
{% set __zoonavigator_api_version = zoonavigator_api_version | default('latest') -%}
{% set __ksql_db_version = ksql_db_version | default('latest') -%}
{% set __schema_registry_ui_version = schema_registry_ui_version | default('latest') -%}

{% set __kafka_connect_ui_version = kafka_connect_ui_version | default('latest') -%}
{% set __kafka_manager_version = kafka_manager_version | default('latest') -%}
{% set __kafka_kafdrop_version = kafka_kafdrop_version | default('latest') -%}
{% set __kafka_kadmin_version = kafka_kadmin_version | default('latest') -%}
{% set __kafka_kafkahq_version = kafka_kafkahq_version | default('latest') -%}
{% set __kafka_burrow_version = kafka_burrow_version | default('latest') -%}
{% set __kafka_burrow_ui_version = kafka_burrow_ui_version | default('latest') -%}
{% set __kafka_burrow_dashboard_version = kafka_burrow_dashboard_version | default('latest') -%}

{% set __tvd_hadoop_version = tvd_hadoop_version | default('latest') -%}

{% set __tvd_spark_version = tvd_spark_version | default('latest') -%}
{% set __tvd_spark_livy_version = tvd_spark_livy_version | default('latest') -%}

{% set __hive_version = hive_version | default('latest') -%}

{% set __tvd_atlas_verion = tvd_atlas_verion | default('latest') -%}

{% set __cassandra_version = cassandra_version | default('latest') -%}

{% set __elasticsearch_version = elasticsearch_version | default('latest') -%}
{% set __dejavu_version = dejavu_version | default('latest') -%}
{% set __cerebro_version = cerebro_version | default('latest') -%}
{% set __elasticsearchhq_version = elasticsearchhq_version | default('latest') -%}


{% set __amundsen_frontend_version = amundsen_frontend_version | default('latest') -%}
{% set __amundsen_search_version = amundsen_search_version | default('latest') -%}
{% set __amundsen_metadata_version = amundsen_metadata_version | default('latest') -%}

{% set __hue_version = hue_version | default('latest') -%}
{% set __hue_postgres_version = hue_postgres_version | default('latest') -%}

{% set __tvd_streamsets_version = tvd_streamsets_version | default('latest') -%}

{% set __nifi_version = nifi_version | default('latest') -%}

{% set __tvd_zeppelin_version = tvd_zeppelin_version | default('latest') -%}

{% set __jupyter_version = jupyter_version | default('latest') -%}

{% set __graphana_version = graphana_version | default('latest') -%}

{% set __kibana_version = kibana_version | default('latest') -%}


{% set __redis_version = redis_version | default('latest') -%}
{% set __redis_commander_version = redis_commander_version | default('latest') -%}

{% set __mongodb_version = mongodb_version | default('latest') -%}
{% set __mongo_express_version = mongo_express_version | default('latest') -%}
{% set __mongo_admin_version = mongo_admin_version | default('latest') -%}

{% set __solr_version = solr_version | default('latest') -%}

{% set __neo4j_version = neo4j_version | default('latest') -%}

{% set __tile38_version = tile38_version | default('latest') -%}

{% set __mysql_version = mysql_version | default('latest') -%}
{% set __postgres_version = postgres_version | default('latest') -%}
{% set __sqlserver_version = sqlserver_version | default('latest') -%}
{% set __adminer_version = adminer_version | default('latest') -%}

{% set __axon_version = axon_version | default('latest') -%}

{% set __mosquitto_version = mosquitto_version | default('latest') -%}
{% set __hivemq3_version = hivemq3_version | default('latest') -%}
{% set __hivemq_mqtt_web_client_version = hivemq_mqtt_web_client_version | default('latest') -%}
{% set __activemq_version = activemq_version | default('latest') -%}

{% set __ftp_pureftpd_version = ftp_pureftpd_version | default('latest') -%}
{% set __ftp_filezilla_version = ftp_filezilla_version | default('latest') -%}

{% set __minio_version = minio_version | default('latest') -%}
{% set __awscli_version = awscli_version | default('latest') -%}
{% set __portainer_version = portainer_version | default('latest') %}


services:

{% if ZOOKEEPER_enabled | default(false) %}
  # Zookeeper ===============================================

  {% for num in range(ZOOKEEPER_nodes | default('1') ) %}
  zookeeper-{{loop.index}}:
    image: confluentinc/cp-zookeeper:{{__confluent_platform_version}}
    container_name: zookeeper-{{loop.index}}
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: {{container_restart_policy}}
  {% endfor %}

  zoonavigator:
    image: elkozmon/zoonavigator-web:{{__zoonavigator_version}}
    container_name: zoonavigator
    ports:
     - "28047:8010"
    environment:
      WEB_HTTP_PORT: 8010
      API_HOST: "zoonavigator-api"
      API_PORT: 9010
    depends_on:
     - zoonavigator-api
    restart: {{container_restart_policy}}

  zoonavigator-api:
    image: elkozmon/zoonavigator-api:{{__zoonavigator_api_version}}
    container_name: zoonavigator-api
    ports:
     - "28048:9010"
    environment:
      API_HTTP_PORT: 9010

{% endif %}   {# zookeeper_enabled #}



{% if KAFKA_enabled | default(false) %}
# Kafka ===============================================
  {% for num in range(KAFKA_broker_nodes | default(1) ) %}
  {% set port = 9091 + loop.index %}
  broker-{{loop.index}}:
    image: confluentinc/cp-kafka:{{__confluent_platform_version}}
    container_name: broker-{{loop.index}}
    depends_on:
      - zookeeper-1
    ports:
      - "{{port}}:{{port}}"
    {% if KAFKA_volume_map_data %}
    volumes:
      - "./container-volume/broker-{{loop.index}}:/var/lib/kafka/data"
    {% endif %}
    environment:
      KAFKA_BROKER_ID: {{loop.index}}
      KAFKA_BROKER_RACK: 'r{{loop.index}}'
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-1:2181'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://${PUBLIC_IP}:{{port}}'
#      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_DELETE_TOPIC_ENABLE: '{{ KAFKA_delete_topic_enable | default(omit) }}'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: '{{ KAFKA_auto_create_topics_enable | default(omit) }}'
      KAFKA_JMX_PORT: {{9093 + loop.index}}
      KAFKA_JMX_OPTS: '-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.rmi.port={{9093 + loop.index}}'
      KAFKA_JMX_HOSTNAME: 'broker-{{loop.index}}'
    restart: {{container_restart_policy}}

  {% endfor %}

{% endif %} {# KAFKA_enabled #}

{% if ( KAFKA_enabled and KAFKA_schema_registry_enabled ) | default(false) %}
  {% for num in range(KAFKA_schema_registry_nodes | default(1) ) %}
    {% set external_port = 28030 + loop.index - 1 %}
    {% set port = 8081 + loop.index - 1 %}
  schema-registry-{{loop.index}}:
    image: confluentinc/cp-schema-registry:{{__confluent_platform_version}}
    hostname: schema-registry-{{loop.index}}
    container_name: schema-registry-{{loop.index}}
    depends_on:
      - zookeeper-1
      - broker-1
    ports:
      - "{{external_port}}:{{port}}"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-{{loop.index}}
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper-1:2181'
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker-1:9092'
      SCHEMA_REGISTRY_MASTER_ELIGIBILITY: "true"
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: {{KAFKA_schema_registry_replication_factor}}
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,OPTIONS'
    restart: {{container_restart_policy}}
  {% endfor %}
{% endif %}   {# KAFKA_enabled and KAFKA_schema_registry_enabled #}

{% if ( KAFKA_enabled and KAFKA_connect_enabled ) | default(false) %}
  {% for num in range(KAFKA_connect_nodes | default(1) ) %}
    {% set external_port = 28013 + loop.index - 1 %}
    {% set port = 8083 + loop.index - 1 %}
  connect-{{loop.index}} :
    image: confluentinc/cp-kafka-connect:{{__confluent_platform_version}}
    container_name: connect-{{loop.index}}
    depends_on:
      - zookeeper-1
      - broker-1
      - schema-registry-1
    ports:
      - "{{external_port}}:{{port}}"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker-1:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect-{{loop.index}}
      CONNECT_REST_PORT: {{port}}
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry-1:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry-1:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka_connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka_connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper-1:2181'
      CONNECT_PLUGIN_PATH: "/usr/share/java,/etc/kafka-connect/custom-plugins"
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-4.0.0.jar
      AWS_ACCESS_KEY_ID: V42FCGRVMK24JJ8DHUYG
      AWS_SECRET_ACCESS_KEY: bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza
    volumes:
      - $PWD/kafka-connect:/etc/kafka-connect/custom-plugins
    restart: {{container_restart_policy}}

  {% endfor %}
{% endif %}   {# KAFKA_enabled and KAFKA_connect_enabled  #}

{% if (KAFKA_enabled and KAFKA_ksqldb_enabled )| default(false) %}
  {% for num in range(KAFKA_ksqldb_nodes | default(1) ) %}
    {% set external_port = 28034 + loop.index - 1 %}
    {% set port = 8088 + loop.index - 1 %}
  ksqldb-server-{{loop.index}} :
    image: confluentinc/ksqldb-server:{{__ksql_db_version}}
    hostname: ksqldb-server-{{loop.index}}
    container_name: ksqldb-server-{{loop.index}}
    ports:
      - "{{external_port}}:{{port}}"
    depends_on:
      - broker-1
      - schema-registry-1
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties"
      KSQL_BOOTSTRAP_SERVERS: "broker-1:9092"
      KSQL_HOST_NAME: ksqldb-server-{{loop.index}}
      KSQL_APPLICATION_ID: "kafka-demo"
      KSQL_LISTENERS: http://0.0.0.0:{{port}}
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_SERVICE_ID: "kafka-demo"
    volumes:
      - $PWD/ksql:/etc/ksql/ext
    restart: {{container_restart_policy}}
  {% endfor %}

  ksqldb-cli:
    image: confluentinc/ksqldb-cli:{{__ksql_db_version}}
    container_name: ksqldb-cli
    depends_on:
      - ksqldb-server-1
    entrypoint: /bin/sh
    tty: true
{% endif %}   {# KAFKA_broker_enabled and KAFKA_ksqldb_enabled #}


{% if (KAFKA_enabled and KAFKA_restproxy_enabled) | default(false) %}
  kafka-rest-1:
    image: confluentinc/cp-kafka-rest:{{__confluent_platform_version}}
    container_name: rest-proxy-1
    depends_on:
      - broker-1
      - schema-registry-1
    ports:
      - "28012:8086"
    environment:
      KAFKA_REST_ZOOKEEPER_CONNECT: '${DOCKER_HOST_IP}:2181'
      KAFKA_REST_LISTENERS: 'http://0.0.0.0:8086'
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry-1:8081'
      KAFKA_REST_HOST_NAME: 'rest-proxy'
    restart: {{container_restart_policy}}
{% endif %}   {# KAFKA_enabled and KAFKA_ksqldb_enabled #}


{% if (KAFKA_enabled and KAFKA_mqttproxy_enabled) | default(false) %}
  kafka-mqtt-1:
    image: confluentinc/cp-kafka-mqtt:{{__confluent_platform_version}}
    hostname: mqtt-proxy
    ports:
      - "28001:1882"
    environment:
      KAFKA_MQTT_TOPIC_REGEX_LIST: 'truck_position:.*position,truck_engine:.*engine'
      KAFKA_MQTT_LISTENERS: 0.0.0.0:1882
      KAFKA_MQTT_BOOTSTRAP_SERVERS: PLAINTEXT://broker-1:9092,broker-2:9093
      KAFKA_MQTT_CONFLUENT_TOPIC_REPLICATIN_FACTOR: 1
{% endif %}   {# KAFKA_enabled and KAFKA_mqttproxy_enabled #}

{% if (KAFKA_enabled and KAFKA_schema_registry_ui_enabled) | default(false) %}
  schema-registry-ui:
      image: landoop/schema-registry-ui:{{__schema_registry_ui_version}}
      container_name: schema-registry-ui
      depends_on:
        - broker-1
        - schema-registry-1
      ports:
        - "28039:8000"
      environment:
        SCHEMAREGISTRY_URL: 'http://${PUBLIC_IP}:28030'
      restart: {{container_restart_policy}}
{% endif %}   {# KAFKA_enabled and KAFKA_schema_registry_ui_enabled #}

{% if (KAFKA_enabled and KAFKA_connect_enabled and KAFKA_connect_ui_enabled) | default(false) %}
  kafka-connect-ui:
    image: landoop/kafka-connect-ui:{{__kafka_connect_ui_version}}
    container_name: kafka-connect-ui
    ports:
      - "28038:8000"
    environment:
      CONNECT_URL: "http://${PUBLIC_IP}:28013/,http://${PUBLIC_IP}:28014/"
      PROXY: "true"
    depends_on:
      - connect-1
    restart: {{container_restart_policy}}
{% endif %}   {# KAFKA_enabled and KAFKA_connect_ui_enabled #}

{% if (KAFKA_enabled and KAFKA_manager_enabled) | default(false) %}
  kafka-manager:
    image: trivadis/kafka-manager:{{__kafka_manager_version}}
    container_name: kafka-manager
    hostname: kafka-manager
    depends_on:
      - zookeeper-1
      - broker-1
    ports:
      - "28044:9000"
    environment:
      ZK_HOSTS: 'zookeeper-1:2181'
      APPLICATION_SECRET: 'abc123!'
    restart: {{container_restart_policy}}
{% endif %}   {#  KAFKA_enabled and KAFKA_manager_enabled #}


{% if (KAFKA_enabled and KAFKA_kafdrop_enabled) | default(false) %}
  kafdrop:
    image: thomsch98/kafdrop:{{__kafka_kafdrop_version}}
    container_name: kafdrop
    ports:
      - "28045:9020"
    environment:
      ZK_HOSTS: zookeeper-1:2181
      LISTEN: 9020
    restart: {{container_restart_policy}}
{% endif %}   {#  KAFKA_enabled and KAFKA_kafdrop_enabled #}

{% if (KAFKA_enabled and KAFKA_kadmin_enabled) | default(false) %}
  kadmin:
    image: hasnat/kadmin:{{__kafka_kadmin_version}}
    container_name: kadmin
    ports:
      - "28040:8080"
    environment:
      ZOOKEEPER_HOST: zookeeper-1:2181
      KAFKA_HOST: broker-1:9092
      #SECURITY_PROTOCOL: SSL
      TRUST_STORE_LOCATION: ssl/client.truststore.jks
      TRUST_STORE_PASSWORD: password
      KEY_STORE_LOCATION: ssl/server.keystore.jks
      KEY_STORE_PASSWORD: password
      KEY_PASSWORD: password
    restart: {{container_restart_policy}}
{% endif %}   {#  KAFKA_enabled and KAFKA_kadmin_enabled #}


{% if (KAFKA_enabled and KAFKA_kafkahq_enabled) | default(false) %}
  kafkahq:
    image: tchiotludo/kafkahq:{{kafka_kafkahq_version}}
    container_name: kafkahq
    ports:
      - 28042:8080
    environment:
      KAFKAHQ_CONFIGURATION: |
        kafkahq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "broker-1:9092"
              schema-registry:
                url: "http://schema-registry-1:8081"
              connect:
                url: "http://connect-1:8083"
    depends_on:
      - broker-1
    restart: {{container_restart_policy}}
{% endif %}   {#  KAFKA_enabled and KAFKA_kafkahq_enabled #}


{% if (KAFKA_enabled and KAFKA_burrow_enabled) | default(false) %}
  burrow:
    image: gschmutz/linkedin-burrow:{{__kafka_burrow_version}}
    container_name: burrow
    volumes:
      - ./conf/burrow:/etc/burrow/
      - ./tmp:/var/tmp/burrow
    ports:
      - 28104:8000
    depends_on:
      - zookeeper-1
      - broker-1
    restart: {{container_restart_policy}}

  burrow-ui:
    image: generalmills/burrowui:{{__kafka_burrow_ui_version}}
    container_name: burrow-ui
    ports:
      - 28104:3000
    environment:
      - BURROW_HOME="http://${PUBLIC_IP}:28104/v3/kafka"
    depends_on:
      - zookeeper-1
      - broker-1
    restart: {{container_restart_policy}}
  burrow-dashboard:
    image: joway/burrow-dashboard:{{__kafka_burrow_dashboard_version}}
    container_name: burrow-dashboard
    ports:
      - 28103:80
    environment:
      - BURROW_BACKEND="http://${PUBLIC_IP}:28104"
    depends_on:
      - zookeeper-1
      - broker-1
    restart: {{container_restart_policy}}
{% endif %}   {# KAFKA_enabled and KAFKA_burrow_enabled #}



{% if HADOOP_enabled | default(false) %}

# Hadoop ===============================================
  namenode:
    image: trivadis/apache-hadoop-namenode:{{__tvd_hadoop_version}}
    container_name: namenode
    hostname: namenode
    volumes:
      - ./container-volume/namenode:/hadoop/dfs/name
      - ./data-transfer:/tmp/data-transfer
    ports:
      - "28084:9870"
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./conf/hadoop.env
    restart: {{container_restart_policy}}

  {% for num in range(HADOOP_datanodes| default(1) ) %}
    {% set external_port = 28085 + loop.index - 1 %}

  datanode-{{loop.index}}:
    image: trivadis/apache-hadoop-datanode:{{__tvd_hadoop_version}}
    container_name: datanode-{{loop.index}}
    volumes:
      - ./container-volume/datanode-{{loop.index}}:/hadoop/dfs/data
    ports:
      - "{{external_port}}:9864"
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./conf/hadoop.env
    restart: {{container_restart_policy}}
  {% endfor %}

  resourcemanager:
    image: trivadis/apache-hadoop-resourcemanager:{{__tvd_hadoop_version}}
    container_name: resourcemanager
    hostname: resourcemanager
    ports:
      - "8088:8088"
    depends_on:
      - namenode
      - datanode-1
    env_file:
      - ./conf/hadoop.env
    environment:
      - YARN_CONF_yarn_resourcemanager_webapp_address=${PUBLIC_IP}:8088
      - YARN_CONF_yarn_nodemanager_webapp_address=${PUBLIC_IP}:8042
      - YARN_CONF_yarn_timeline___service_webapp_address=${PUBLIC_IP}:28020
      - YARN_CONF_yarn_log_server_url=${PUBLIC_IP}:28020
    restart: {{container_restart_policy}}

  nodemanager:
    image: trivadis/apache-hadoop-nodemanager:{{__tvd_hadoop_version}}
    container_name: nodemanager
    hostname: nodemanager
    ports:
      - "8042:8042"
    depends_on:
      - namenode
      - datanode-1
      - datanode-2
    env_file:
      - ./conf/hadoop.env
    environment:
      - YARN_CONF_yarn_resourcemanager_webapp_address=${PUBLIC_IP}:8088
      - YARN_CONF_yarn_nodemanager_webapp_address=${PUBLIC_IP}:8042
      - YARN_CONF_yarn_timeline___service_webapp_address=${PUBLIC_IP}:28020
      - YARN_CONF_yarn_log_server_url=${PUBLIC_IP}:28020
    restart: {{container_restart_policy}}

  historyserver:
    image: trivadis/apache-hadoop-historyserver:{{__tvd_hadoop_version}}
    container_name: historyserver
    hostname: historyserver
    ports:
      - "28020:8188"
    depends_on:
      - namenode
      - datanode-1
    env_file:
      - ./conf/hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode-1:9864 datanode-2:9864 resourcemanager:8088"
    restart: {{container_restart_policy}}

  hadoop-client:
    image: trivadis/apache-hadoop-client:{{__tvd_hadoop_version}}
    container_name: hadoop-client
    hostname: hadoop-client
    env_file:
      - ./conf/hadoop.env
    command: tail -f /dev/null
    restart: {{container_restart_policy}}

{% endif %}   {#  HADOOP_enabled #}


{% if SPARK_enabled | default(false) %}
# Spark ===============================================
  spark-master:
    image: trivadis/apache-spark-master:{{__tvd_spark_version}}
    container_name: spark-master
    hostname: spark-master
    ports:
      - 6066:6066
      - 7077:7077
      - 28076:8080
    env_file:
      - ./conf/hadoop.env
    environment:
      - SPARK_PUBLIC_DNS=${PUBLIC_IP}
      - INIT_DAEMON_STEP=setup_spark
#      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    volumes:
      - ./conf/spark/spark-defaults.conf:/spark/conf/spark/spark-defaults.conf
    restart: {{container_restart_policy}}


  {% for num in range(SPARK_workers | default(1) ) %}
      {% set external_port = 28077 + loop.index - 1 %}
      {% set webui_port = 28077 + loop.index - 1 %}


  spark-worker-{{loop.index}}:
    image: trivadis/apache-spark-worker:{{__tvd_spark_version}}
    container_name: spark-worker-{{loop.index}}
    hostname: spark-worker-{{loop.index}}
    depends_on:
      - spark-master
    ports:
      - "{{external_port}}:{{external_port}}"
    env_file:
      - ./conf/hadoop.env
    environment:
      SPARK_MASTER: "spark://spark-master:7077"
#      SPARK_WORKER_CORES: 2
#      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_WEBUI_PORT: "{{webui_port}}"
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
    volumes:
      - ./conf/spark/spark-defaults.conf:/spark/conf/spark/spark-defaults.conf
    restart: {{container_restart_policy}}

  {% endfor %}

  # Initialize the folder for Spark logs in HDFS
  hadoop-setup:
    image: trivadis/apache-hadoop-client:{{__tvd_hadoop_version}}
    hostname: hadoop-setup
    container_name: hadoop-setup
    env_file:
      - ./conf/hadoop.env
    depends_on:
      - namenode
    entrypoint: "bash -c 'echo Waiting for Hadoop to be ready... && \
                       dockerize -wait tcp://namenode:9870 -timeout 120s && \
                       hadoop fs -mkdir -p /var/log/spark/logs &&
                       sleep infinity'"

  {% if SPARK_history_enabled | default(false) %}
  spark-history:
    image: trivadis/apache-spark-worker:{{__tvd_spark_version}}
    command: /spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer
    container_name: spark-history
    hostname: spark-history
    expose:
      - 18080
    ports:
      - 28072:18080
    volumes:
      - ./conf/spark/spark-defaults.conf:/spark/conf/spark/spark-defaults.conf
    restart: {{container_restart_policy}}
  {% endif %}   {#  SPARK_history_enabled #}

  {% if SPARK_thrift_enabled | default(false) %}
  spark-thrift-server:
    image: trivadis/apache-spark-master:{{__tvd_spark_version}}
    container_name: spark-thrift-server
    ports:
      - "28073:10000"
    env_file:
      - ./conf/hadoop.env
    volumes:
      - ./conf/hive-site.xml:/spark/conf/hive-site.xml
      - ./conf/spark/spark-defaults.conf:/spark/conf/spark/spark-defaults.conf
    command: bash -c "sleep 2m && /spark/sbin/start-thriftserver.sh && tail -f /spark/logs/spark--org.apache.spark.sql.hive.thriftserver.HiveThriftServer2-*.out"
  {% endif %}   {#  SPARK_thrift_enabled #}

  {% if SPARK_livy_enabled | default(false) %}
  livy:
    image: trivadis/apache-livy:{{tvd_spark_livy_version}}
    container_name: livy
    hostname: livy
    env_file:
      - ./conf/hadoop.env
    volumes:
      - ./conf/spark/spark-defaults.conf:/spark/conf/spark-defaults.conf
    ports:
      - "28021:8998"
    environment:
      - SPARK_MASTER=yarn
      - DEPLOY_MODE=cluster
    restart: always
  {% endif %}   {#  SPARK_livy_enabled #}
{% endif %}   {#  SPARK_enabled #}


{% if HIVE_enabled | default(false) %}
# Hive ===============================================
  hive-server:
    image: johannestang/hive:{{__hive_version}}
    container_name: hive-server
    hostname: hive-server
    ports:
      - "28027:10000"
      - "28028:10002"
    env_file:
      - ./conf/hadoop.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
#      HDFS_CONF_fs_s3a_access_key: ${MINIO_ACCESS_KEY}
#      HDFS_CONF_fs_s3a_secret_key: ${MINIO_SECRET_KEY}
    restart: {{container_restart_policy}}

  hive-metastore:
    image: johannestang/hive:{{__hive_version}}
    container_name: hive-metastore
    hostname: hive-metastore
    ports:
      - "28026:9083"
    env_file:
      - ./conf/hadoop.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      - "SERVICE_PRECONDITION=namenode:9870 datanode-1:9864 hive-metastore-db:5432"
    restart: {{container_restart_policy}}

  hive-metastore-db:
    container_name: hive-metastore-db
    hostname: hive-metastore-db
    image: bde2020/hive-metastore-postgresql:2.3.0
    restart: {{container_restart_policy}}
{% endif %}   {#  HIVE_enabled #}


{% if ATLAS_enabled  | default(false) %}
# Governance ===============================================
  atlas:
    image: trivadis/apache-atlas:{{__tvd_atlas_verion}}
    container_name: atlas
    hostname: atlas
    ports:
      - 28105:21000
    environment:
      - ATLAS_PROVISION_EXAMPLES=true
    volumes:
      - ./conf/atlas/atlas-application.properties:/opt/atlas/conf/atlas-application.properties
      - ./conf/atlas/users-credentials.properties:/opt/atlas/conf/users-credentials.properties
      - ./conf/atlas/credentials:/tmp/credentials
    depends_on:
      - zookeeper-1
      - broker-1
      - atlas-kafka-setup
      - cassandra-atlas
    restart: {{container_restart_policy}}

  {% if KAFKA_enabled  | default(false) %}
  atlas-kafka-setup:
    image: confluentinc/cp-kafka:{{__confluent_platform_version}}
    hostname: atlas-kafka-setup
    container_name: atlas-kafka-setup
    depends_on:
      - broker-1
      - zookeeper-1
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b broker-1:9092 1 120 && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 1 --replication-factor 1 --topic ATLAS_HOOK && \
                       kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --partitions 1 --replication-factor 1 --topic ATLAS_ENTITIES'"
    environment:
      # The following settings are listed here only to satisfy the image's requirements.
      # We override the image's `command` anyways, hence this container will not start a broker.
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored
  {% endif %} {#  KAFKA_enabled #}

  cassandra-atlas:
    image: cassandra:{{__cassandra_version}}
    container_name: cassandra-atlas
    hostname: cassandra-atlas
    ports:
      - "28062:9042"
      - "28064:9160"
    environment:
      - CASSANDRA_START_RPC=true
    restart: {{container_restart_policy}}

  elasticsearch-atlas:
    image: docker.elastic.co/elasticsearch/elasticsearch:{{elasticsearch_version}}
    container_name: elasticsearch-atlas
    hostname: elasticsearch-atlas
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "http.host=0.0.0.0"
      - "network.host=0.0.0.0"
      - "transport.host=127.0.0.1"
      - "cluster.name=docker-cluster"
      - "xpack.security.enabled=false"
      - "discovery.zen.minimum_master_nodes=1"
    ports:
      - "28065:9200"
    restart: {{container_restart_policy}}

 {% if AMUNDSEN_enabled  | default(false) %}
  amundsenfrontend:
    image: amundsendev/amundsen-frontend:{{__amundsen_frontend_version}}
    container_name: amundsenfrontend
    depends_on:
      - amundsenmetadata
      - amundsensearch
    ports:
      - 28003:5000
    environment:
      - METADATASERVICE_BASE=http://amundsenmetadata:5000
      - SEARCHSERVICE_BASE=http://amundsensearch:5000
    restart: {{container_restart_policy}}

  amundsensearch:
    image: amundsendev/amundsen-search:{{__amundsen_search_version}}
    container_name: amundsensearch
    ports:
      - 28004:5000
    depends_on:
      - elasticsearch
    environment:
      - CREDENTIALS_PROXY_USER=admin
      - CREDENTIALS_PROXY_PASSWORD=abc123!
      - PROXY_ENDPOINT=atlas:21000
      - PROXY_CLIENT=ATLAS
    restart: {{container_restart_policy}}

  amundsenmetadata:
    image: amundsendev/amundsen-metadata:{{__amundsen_metadata_version}}
    container_name: amundsenmetadata
    depends_on:
      - atlas
    ports:
      - 28005:5000
    environment:
      - CREDENTIALS_PROXY_USER=admin
      - CREDENTIALS_PROXY_PASSWORD=abc123!
      - PROXY_HOST=atlas
      - PROXY_PORT=21000
      - PROXY_CLIENT=ATLAS
    restart: {{container_restart_policy}}
  {% endif %}   {#  AMUNDSEN_enabled #}
{% endif %}   {#  ATLAS_enabled #}

{% if (HUE_enabled and SOLR_enabled)  | default(false) %}
  # Data Engineering Tools ===============================================

  hue:
    image: gethue/hue:{{__hue_version}}
    container_name: hue
    hostname: hue
    dns: 8.8.8.8
    ports:
      - "28043:8888"
    volumes:
      - ./conf/hue.ini:/usr/share/hue/desktop/conf/hue.ini
    depends_on:
      - hue-db
      - solr
    restart: {{container_restart_policy}}

  hue-db:
    image: postgres:{{__hue_postgres_version}}
    container_name: hue-db
    hostname: hue-db
    environment:
      POSTGRES_DB: hue
      POSTGRES_PASSWORD: hue
      POSTGRES_USER: hue
    restart: {{container_restart_policy}}

{% endif %}   {#  HUE_enabled and SOLR_enabled #}

{%if STREAMSETS_enabled | default(false) %}
  streamsets:
    image: trivadis/streamsets-kafka-hadoop-aws:{{__tvd_streamsets_version}}
    container_name: streamsets
    hostname: streamsets
    ports:
      - "28029:18630"
    environment:
      SDC_OFFSET_DIRECTORY: /data/custom-offset-el
      SDC_JAVA_OPTS: "-Xmx2g -Xms2g"
      SDC_JAVA8_OPTS: "-XX:+UseG1GC"
      SDC_CONF_MONITOR_MEMORY: "true"
      SDC_CONF_PIPELINE_MAX_RUNNERS_COUNT: 50
    volumes:
#      - ./container-volume/streamsets/data:/data:Z
#      - ./streamsets-extras/streamsets-libs-extras/streamsets-datacollector-jdbc-lib/postgresql-42.2.6.jar:/opt/streamsets-datacollector-{{__tvd_streamsets_version}}/streamsets-libs-extras/streamsets-datacollector-jdbc-lib/lib/postgresql-42.2.6.jar:Z
#      - ./streamsets-extras/libs-common-lib:/opt/streamsets-datacollector-{{__tvd_streamsets_version}}/libs-common-lib:Z
#      - ./streamsets-extras/user-libs:/opt/streamsets-datacollector-user-libs:Z
    restart: {{container_restart_policy}}
{% endif %}   {#  STREAMSETS_enabled  #}

{%if STREAMSETS_enabled | default(false) %}

  nifi:
    image: apache/nifi:{{__nifi_version}}
    container_name: nifi
    hostname: nifi
    ports:
      - "28054:8080"
    restart: {{container_restart_policy}}

{% endif %}   {#  STREAMSETS_enabled  #}



{%if ZEPPELIN_enabled | default(false) %}
# Data Science Tools ===============================================
  zeppelin:
    image: trivadis/apache-zeppelin:{{__tvd_zeppelin_version}}
    container_name: zeppelin
    hostname: zeppelin
    ports:
      - "28055:8080"
#      - "4040:4040"
#      - "42331:42331"
    env_file:
      - ./conf/hadoop.env
    environment:
      # AWS Credentials
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}

      ZEPPELIN_ADDR: "0.0.0.0"
      ZEPPELIN_PORT: "8080"
      ZEPPELIN_INTERPRETER_CONNECT_TIMEOUT: 120000
      SPARK_MASTER: "spark://spark-master:7077"

      # set spark-master for Zeppelin interpreter
      MASTER: "spark://spark-master:7077"
      SPARK_DRIVER_HOST: zeppelin
      SPARK_DRIVER_BINDADDRESS: "0.0.0.0"
      PYSPARK_PYTHON: "python3"
# no longer necessary with 0.8.2 of Zepplin
#      - SPARK_SUBMIT_OPTIONS="--packages org.apache.commons:commons-lang3:3.5"
      # enableV4 to make it work with AWS Frankfurt region
      SPARK_SUBMIT_OPTIONS: "--conf spark.driver.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4 --conf spark.executor.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4"
    volumes:
      - ./conf/spark/spark-defaults.conf:/spark/conf/spark/spark-defaults.conf
      - ./conf/zeppelin/shiro.ini:/opt/zeppelin/conf/shiro.ini
      - ./conf/zeppelin/interpreter-setting.json:/opt/zeppelin/interpreter/spark/interpreter-setting.json
      - ./data-transfer:/data-transfer
    restart: {{container_restart_policy}}
{% endif %}   {#  ZEPPELIN_enabled  #}

{%if JUPYTER_enabled | default(false) %}
# Data Science Tools ===============================================
  # make sure to get Spark to fit with the version of spark master
  # - 2.4.0 tag 59b402ce701d
  # - 2.4.3 tag abdb27a6dfbb
  jupyter:
    image: jupyter/all-spark-notebook:{{__jupyter_version}}
    container_name: jupyter
    hostname: jupyter
    ports:
      - "28060:8888"
    environment:
      JUPYTER_ENABLE_LAB: "true"
      JUPYTER_TOKEN: "abc123!"
      GRANT_SUDO: "true"
      TINI_SUBREAPER: "true"
    restart: {{container_restart_policy}}

{% endif %}   {#  JUPYTER_enabled  #}



{% if GRAFANA_enabled | default(false) %}
# Data Visualization ===============================================
  grafana:
    image: grafana/grafana:{{__graphana_version}}
    hostname: grafana
    container_name: grafana
    ports:
      - "28099:3000"
    restart: {{container_restart_policy}}
{% endif %}   {#  GRAFANA_enabled #}




{% if REDIS_enabled | default(false) %}
# NoSQL ===============================================
  redis:
    container_name: redis
    hostname: redis:{{__redis_version}}
    image: redis
    ports:
      - 6379:6379
    restart: {{container_restart_policy}}

  redis-commander:
    container_name: redis-commander
    hostname: redis-commander
    image: rediscommander/redis-commander:{{__redis_commander_version}}
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "28057:8081"
    restart: {{container_restart_policy}}
{% endif %}   {#  REDIS_enabled #}

{% if CASSANDRA_enabled | default(false) %}
# NoSQL ===============================================
  cassandra-1:
    image: cassandra:{{__cassandra_version}}
    container_name: cassandra-1

    ports:
      - 28090:9042
      - 7199:7199
      - 9160:9160
    environment:
      - CASSANDRA_SEEDS=cassandra-1
      - CASSANDRA_CLUSTER_NAME="Test Cluster"
      - CASSANDRA_DC=se1
      - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
    restart: {{container_restart_policy}}

  cassandra-web:
    image: trivadis/cassandra-web
    container_name: cassandra-web
    ports:
      - "28053:3000"
    environment:
      - CASSANDRA_HOSTNAME=cassandra-1
      - CASSANDRA_PORT=9042
      - CASSANDRA_USERNAME=cassandra
      - CASSANDRA_PASSWORD=cassandra
    restart: {{container_restart_policy}}
{% endif %}   {#  CASSANDRA_enabled #}

{% if MONGODB_enabled | default(false) %}
# NoSQL ===============================================
  mongodb:
    image: mongo:{{__mongodb_version}}
    container_name: mongodb
    ports:
      - 27017:27017
    environment:
      - MONGO_INITDB_DATABASE=sample
      - MONGO_INITDB_USERNAME=admin
      - MONGO_INITDB_PASSWORD=admin
    volumes:
      # seeding scripts
      - ./conf/mongo-entrypoint:/docker-entrypoint-initdb.d
    restart: {{container_restart_policy}}

  mongo-express:
    image: mongo-express:{{__mongo_express_version}}
    container_name: mongo-express
    ports:
      - 28056:8081
    environment:
      - ME_CONFIG_MONGODB_SERVER=mongodb
    restart: {{container_restart_policy}}

  admin-mongo:
    image: adicom/admin-mongo:{{__mongo_admin_version}}
    container_name: admin-mongo
    ports:
      - 28051:1234
    restart: {{container_restart_policy}}
{% endif %}   {#  MONGODB_enabled #}

{% if SOLR_enabled | default(false) %}
# NoSQL ===============================================
  solr:
    image: solr:{{__solr_version}}
    container_name: solr
    ports:
      - "28081:8983"
    restart: {{container_restart_policy}}
{% endif %}   {#  SOLR_enabled #}

{% if ELASTICSEARCH_enabled | default(false) %}
# NoSQL ===============================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:{{__elasticsearch_version}}
    hostname: elasticsearch
    container_name: elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      XPACK_SECURITY_ENABLED: "false"
      xpack.monitoring.enabled: "false"
    restart: {{container_restart_policy}}

  dejavu:
    image: appbaseio/dejavu:{{__dejavu_version}}
    hostname: dejuvu
    container_name: dejavu
    ports:
      - "28000:1358"
    restart: {{container_restart_policy}}

  cerebro:
    image: lmenezes/cerebro:{{__cerebro_version}}
    hostname: cerebro
    container_name: cerebro
    ports:
      - "28061:9000"
    restart: {{container_restart_policy}}

  elastichq:
    image: elastichq/elasticsearch-hq:{{__elasticsearchhq_version}}
    hostname: elatichq
    container_name: elastichq
    ports:
      - "28052:5000"

  {% if KIBANA_enabled | default(false) %}
  kibana:
    image: docker.elastic.co/kibana/kibana:{{__kibana_version}}
    hostname: kibana
    container_name: kibana
    depends_on:
      - elasticsearch
    ports:
      - "28006:5601"
    environment:
      xpack.monitoring.enabled: "false"
      discovery.type: "single-node"
      elasticsearch.url: http://elasticsearch:9200
      server.host: "0.0.0.0"
      SERVER_HOST: "0.0.0.0"
      server.name: "kibana"
      SERVER_NAME: "kibana"
      XPACK_GRAPH_ENABLED: "false"
      XPACK_MONITORING_ENABLED: "false"
      XPACK_REPORTING_ENABLED: "false"
      XPACK_SECURITY_ENABLED: "false"
    command: [ "/bin/bash", "-c", "/usr/share/kibana/bin/kibana-plugin remove x-pack; /usr/local/bin/kibana-docker" ]
    restart: {{container_restart_policy}}
  {% endif %}   {#  KIBANA_enabled #}
{% endif %}   {#  ELASTICSEARCH_enabled #}

{% if NEO4J_enabled | default(false) %}
# NoSQL ===============================================
  neo4j:
    image: neo4j:{{__neo4j_version}}
    hostname: neo4j
    container_name: neo4j
    ports:
      - "28080:7474"
      - "7687:7687"
    environment:
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_dbms_shell_enabled=true
    restart: {{container_restart_policy}}
{% endif %}   {#  NEO4J_enabled #}

{% if TILE38_enabled | default(false) %}
# NoSQL ===============================================
  tile38:
    image: tile38/tile38:{{__tile38_version}}
    container_name: tile38
    ports:
      - "9851:9851"
    restart: {{container_restart_policy}}
{% endif %}   {#  TILE38_enabled #}




{% if MYSQL_enabled | default(false) %}
# RDBMS ===============================================
  mysql:
    image: mysql:{{__mysql_version}}
    container_name: mysql
    ports:
      - 3306:3306
    environment:
      - MYSQL_DATABASE=sample
      - MYSQL_USER=sample
      - MYSQL_PASSWORD=sample
      - MYSQL_ROOT_PASSWORD=manager
      - MYSQL_LOG_CONSOLE=true
    restart: {{container_restart_policy}}
{% endif %}   {#  MYSQL_enabled #}

{% if SQLSERVER_enabled | default(false) %}
# RDBMS ===============================================
  sqlserver:
    image: mcr.microsoft.com/mssql/server:{{__sqlserver_version}}
    hostname: sqlserver
    container_name: sqlserver
    ports:
      - "1433:1433"
    environment:
      ACCEPT_EULA: "Y"
      SA_PASSWORD: "SqlServerAdmin123!"
      MSSQL_PID: "Express"
    restart: {{container_restart_policy}}
{% endif %}   {#  SQLSERVER_enabled #}

{% if POSTGRESQL_enabled | default(false) %}
# RDBMS ===============================================
  postgresql:
    image: mujz/pagila:{{__postgres_version}}
    container_name: postgresql
    environment:
      - POSTGRES_PASSWORD=sample
      - POSTGRES_USER=sample
      - POSTGRES_DB=sample
    restart: {{container_restart_policy}}
{% endif %}   {#  POSTGRESQL_enabled #}

{% if ADMINER_enabled | default(false) %}
  adminer:
    image: adminer:{{__adminer_version}}
    container_name: adminer
    ports:
      - 28041:8080
    restart: {{container_restart_policy}}
{% endif %}   {#  ADMINER_enabled #}

{% if AXON_enabled | default(false) %}
  # Event Store ===============================================

  axon-server:
    image: axoniq/axonserver:{{__axon_version}}
    container_name: axon-server
    hostname: axon-server
    ports:
      - 28010:8024
      - 28018:8124
    environment:
      - AXONSERVER_HOSTNAME=axon-server
      - AXONSERVER_EVENTSTORE=/eventstore
      - AXONSERVER_CONTROLDB=/controldb
      - AXONSERVER_HTTP_PORT=8024
      - AXONSERVER_GRPC_PORT=8124
    restart: {{container_restart_policy}}
{% endif %}   {#  AXON_enabled #}




{% if MQTT_enabled | default(false) %}
#  Data Integration ===============================================

  {% if MOSQUITTO_enabled | default(false) %}
  mosquitto-1:
    image: eclipse-mosquitto:{{__mosquitto_version}}
    hostname: mosquitto-1
    ports:
      - "28100:1883"
      - "28023:9001"
    volumes:
      - ./conf/mosquitto/mosquitto-1.conf:/mosquitto/config/mosquitto.conf
    restart: {{container_restart_policy}}
  {% endif %}   {#  MOSQUITTO_enabled #}

  {% if HIVEMQ_enabled | default(false) %}
  mqtt-1:
    image: hivemq/hivemq3:{{__hivemq3_version}}
    hostname: mqtt-1
    container_name: mqtt-1
    ports:
      - "28101:1883"
      - "28024:8080"
    restart: {{container_restart_policy}}
  {% endif %}   {#  HIVEMQ_enabled #}

  {% if MQTT_UI_enabled | default(false) %}
  mqtt-ui:
    image: vergissberlin/hivemq-mqtt-web-client:{{__hivemq_mqtt_web_client_version}}

    hostname: mqtt-ui
    container_name: mqtt-ui
    restart: {{container_restart_policy}}
    ports:
      - '28082:80'
  {% endif %}   {#  MQTT_UI_enabled #}
{% endif %}   {#  MQTT_enabled #}

{% if ACTIVEMQ_enabled | default(false) %}
  activemq:
    image: rmohr/activemq:{{__activemq_version}}
    container_name: activemq
    ports:
      # mqtt
      - "1883:1883"
      # amqp
      - "28007:5672"
      # ui
      - "28019:8161"
      # stomp
      - "28068:61613"
      # ws
      - "28069:61614"
      # jms
      - "28070:61616"
    volumes:
      - ./container-volume/activemq/data:/opt/activemq/data
    restart: {{container_restart_policy}}
{% endif %}   {#  ACTIVEMQ_enabled #}

{% if FTP_enabled | default(false) %}
  ftp:
    image: stilliard/pure-ftpd:{{__ftp_pureftpd_version}}
    container_name: ftp
    hostname: ftp
    environment:
#      - PUBLICHOST="192.168.73.86"
      - PUBLICHOST=ftp
      - FTP_USER_NAME=orderproc
      - FTP_USER_PASS=orderproc
      - FTP_USER_HOME=/home/ftp-data
      - FTP_MAX_CLIENTS=9
    ports:
      - "21:21"
      - "30000-30009:30000-30009"
    restart: {{container_restart_policy}}

  filezilla:
    image: jlesage/filezilla:{{__ftp_filezilla_version}}
    container_name: filezilla
    volumes:
      - ./data-transfer:/data-transfer
    ports:
      - "28008:5800"
      - "28009:5900"
#    volumes:
#      - "/docker/appdata/filezilla:/config:rw"
#      - "/files:/storage:rw"
    environment:
      - VNC_PASSWORD=admin123
{% endif %}   {#  FTP_enabled #}



{% if MINIO_enabled | default(false) %}
#  Object Store (S3) ===============================================
  minio:
    hostname: minio
    image: minio/minio:{{__minio_version}}
    container_name: minio
    ports:
      - '28083:9000'
#    volumes:
#      - './minio/data/:/data'
#      - './minio/config:/root/.minio'
    environment:
      MINIO_ACCESS_KEY: V42FCGRVMK24JJ8DHUYG
      MINIO_SECRET_KEY: bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza
    command: server /data
    restart: {{container_restart_policy}}
{% endif %}   {#  MINIO_enabled #}

{% if AWSCLI_enabled | default(false) %}
  awscli:
    image: xueshanf/awscli:{{__awscli_version}}
    container_name: awscli
    hostname: awscli
    volumes:
      - './conf/s3cfg:/root/.s3cfg'
      - './data-transfer:/tmp/data-transfer'
#      - './minio/config:/root/.minio'
    environment:
      AWS_ACCESS_KEY_ID: V42FCGRVMK24JJ8DHUYG
      AWS_SECRET_ACCESS_KEY: bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza
    command: tail -f /dev/null
    restart: {{container_restart_policy}}
{% endif %}   {#  AWSCLI_enabled #}




{% if PORTAINER_enabled | default(false) %}
  #  Container UI ===============================================
  portainer:
    image: portainer/portainer:{{__portainer_version}}
    container_name: portainer
    command: --admin-password '$$2y$$05$$NrPTXkUOIHTTbdHUqdAZVuSbncaZ9frWZYXDbA4v/WYqY0nAY1Sui'
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
#      - data_portainer:/data
#    environment:
#      - VIRTUAL_HOST=monitor.bioatlas.se
#      - VIRTUAL_PORT=9000
    ports:
      - 28071:9000
    restart: {{container_restart_policy}}
{% endif %}   {# PORTAINER_enabled #}
